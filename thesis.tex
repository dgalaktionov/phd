%###
% \RequirePackage[l2tabu, orthodox]{nag}
\documentclass[a4paper,10pt,twoside]{book}
% \usepackage[width=127mm,height=191mm,includehead,hcentering,vcentering]{geometry}

% \includeonly{_init,basic-concepts,raster}
% \includeonly{__init,k3tree}

\input{___header}
\makeglossaries

\begin{document}

%\epstopdfsetup{outdir=./}
\pagenumbering{roman}
\pagestyle{fancy}\fancyfoot{}\fancyhead{}
\fancyhead[LO]{\slshape\nouppercase{\rightmark}}
\fancyhead[RE]{\slshape\nouppercase{\leftmark}}
\fancyhead[RO,LE]{\slshape \thepage}

\frontmatter

\input{_acronyms.tex}
\include{_init}

\mainmatter

\chapter{Introduction}
	\section{Motivation}
	In the context of public transportation networks, the last several years have seen numerous advances in wireless technologies, sensor networks (especially those related to RFID) and ubiquitous computing, leading to a widespread adoption of passenger tracking technology by public transportation services, making the collection of large amounts of data about the travel habits of these passengers\footnote{Alternatively called ``users'' in the context of transportation agencies} easier than ever before.
	This in turn has opened the door for the exploitation of this kind of information to study the demand (usage) of a network, as opposed to the well-known techniques to analyze the offer (routes, timetables, etc...). 
	For these applications, it is not the data about individual trajectories but measures of the use of the network what matters for traffic monitoring and road planning tasks. Examples of useful measures are  accessibility and centrality indicators, referred to how easy  is to reach locations or how important certain stops are within a network~\cite{Morency2007193, El-Geneidy2011, Wang2015335}. All these measures are based on some kind of counting queries that determine the number of \textit{distinct} trips that occur within a spatial and/or temporal window.
	To enable these new kinds of demand studies, it is imperative to develop mechanisms to efficiently persist and manage these vast (and always increasing) collections of data. When we also take into account that efficient query patterns need to be supported for this data to be ``useful'', the solution clearly constitutes an emerging technological challenge, that is being approached from several different domains, and hundreds of ad-hoc solutions have been implemented by all the \textit{Smart Cities} around the globe.
	
	%In  transportation systems, new technologies such as automatic fare collection (e.g., smartcards) and automatic passenger counting have made possible to generate a huge amount of highly detailed,
	%real-time data useful to define measures that characterize  a transportation network. This data is particularly useful because it actually consists of real trips, combining  implicitly the service offered by a public transportation system with  the demand for the system. When having this data,  it is not the data about individual trajectories but measures of the use of the network what matters for traffic monitoring and road planning tasks. Examples of useful measures are  accessibility and centrality indicators, referred to how easy  is to reach locations or how important certain stops are within a network~\cite{Morency2007193, El-Geneidy2011, Wang2015335}. All these measures are based on some kind of counting queries that determine the number of \textit{distinct} trips that occur within a spatial and/or temporal window.   
	
	A practical representation for this information that supports efficient indexing would have numerous possible applications. In \cite{tu2018spatial} we can see how it is possible to combine GPS trajectories with \gls{afc} data to recreate complete trajectories and study the ridership by area. Alternatively, in \cite{weng2018mining} the complete trajectories are inferred from the \gls{afc} data, to later analyze behaviour patterns and preferences of the travelers with the goal of improving the efficiency of the network. Another application that is enabled by such analysis is the targeted advertising \cite{zhang2017targeted}, as the interests of a user can be profiled by their travel patterns. Other works focus on analyzing the usage of individual stops or stations, such as \cite{ceapa2012avoiding}, where the authors determine that congestion times in the metro network of London are predictable and occur in narrow time intervals. Armed with such information, an user may choose a different travel pattern to avoid the crowd and enhance their overall experience. When we consider about public transportation over a road network, we can find works centered around studying taxi ridership. One notable example is \cite{yuan2013t}, that discusses a two-way taxi recommendation system, where taxi drivers are pointed to the most profitable parking spaces while passengers are directed to the street segments with a high probability of finding a vacant taxi.
	
	One key observation from all the works referenced above is that a mere collection of trajectories or time-stamped points over a two-dimensional space of latitude and longitude would not be rich enough to perform these studies. They are therefore required to work with a representation that allows for some degree of \textit{semantic} information. At the very least, that information must include references to network elements (stops, lines or streets), and sometimes even some (anonymized) user identifier. Therefore, we require a representation that differs from the traditional spatial indexes and databases, as it must support efficient access methods based on network elements.
	
	\section{Problem definition}
	\label{sec:pd}
	Considering the underlying network, we have identified two distinguishable contexts for public transportation systems:
	\begin{itemize}
	    \item \textbf{Networks based on urban streets}: within these networks, a trajectory can start anywhere, at any time, and follow any arbitrary path of segments along a defined road network.
	    %, which can have two alternative graph representations: assign a vertex for each intersection and edges for road segments that connect these intersections, or alternatively, a vertex for each road segment with no intersections and edges that connect navigable road segments.
	    Trajectories of taxis or bicycles\footnote{Rented bicycles are a public transportation method commonly managed and incentivized by city administrations} fall into this category. For these systems, queries of interest may involve points of interest around which these trajectories could end, or road segments that could be part of a path.
	    \item \textbf{Public transportation networks}: the trajectories must start at predefined points (usually stops or stations) at set times that are defined by the vehicles that make a stop at those points. These vehicles follow a predefined paths along these points, forming routes. Therefore, a trajectory follows a path along a graph of stops as vertexes, where an edge exists if there is a route that connects two stops. This graph can be hold very little relation to a road network, and users that travel in the same vehicle would produce identical parts of trajectories. This holds for bus and metro systems, along with most of other urban transportation systems. It is expected that for a collection of trajectories from a route-based network some of the queries of interest may revolve around the main network elements, which are routes and stops.
	\end{itemize}
	
	\begin{figure*}[t]
		\begin{center}
			\begin{tabular}{cc}
				\includegraphics[width=0.4\textwidth]{figures/road-network.png} &
				\includegraphics[width=0.4\textwidth]{figures/mtl-metro-cut.png} \\
			\end{tabular}
		\end{center}
		\caption{Example of a typical urban street network (left) and a subway network (right).}
		\caption*{\small Sources: \cite{boeing2017osmnx} (left), \url{http://www.stm.info/fr/infos/reseaux/metro} (right)}
		\label{fig:networks}
	\end{figure*}
	
	Regardless of the working context, we will require a \textit{network} model, which tends to be quite simple in urban street networks, merely consisting of a directed graph with street segments as nodes, where connection to other street segments indicate that direct navigation is possible. For public transportation networks, as mentioned above, it could be pertinent to consider a more rich representation than a graph of stops and lines, but considering also the routes formed by transportation vehicles, such as buses or trains, visiting stops at set times and allowing commuters to board or alight at them. A well-known model that includes these network elements, among others less interesting for our problem, is \gls{gtfs}\footnote{\url{https://developers.google.com/transit/gtfs/}}, which is widely adopted by open data platforms in numerous Smart Cities.
	
	For any kind of network, a \textit{trajectory} will be defined as a path formed by a sequence of network elements (usually stops or street segments), that was traversed by a single commuter in one trip, with an origin and a final destination. In this definition, we must consider some practical limitations to the nature of a trajectory, as one could argue whether commuters that take more than one hour to switch a line are actually switching or just finalized their trajectories and are starting second ones with some new destination. These cases are complicated to unambiguously decide in practice, and therefore our approach will tend to set hard limits on waiting times and walking distances for a single trajectory.
	
	Our definitions also require to be able to speak for a concept of time. When we work with a public transportation network model integrating routes formed by transport vehicles that follow lines, there would be no need in representing the exact time at which each user has boarded on a stop, only a route identifier, as the stopping times would be already available in our modelled network, this avoiding some redundancy in the representation of trajectories.
	Alternatively, for urban street networks or other cases where route information is unavailable, a representation of time intervals may be considered in order to achieve a compact representation, where time would be expressed in discrete intervals of one to thirty minutes.
	
	Massive data collection techniques exist for both of the network contexts discussed above, as will be later seen in Section~\ref{sec:dm}, leading to the problem of efficiently handling this vast information. Apart from the usual well-known \textit{Big Data} solutions, there is an ongoing research on the application of data structures for some of these goals. In particular, it is possible to apply many of the techniques from the field of \textit{Compact Data Structures} to build autoindexed representations that support efficient query patterns tailored for specific information needs, while offering some sort of compression with respect of a more traditional representation.
	
	A usable solution would also require a user interface that enables the exploitation of this information by researchers, transportation companies, city administrations and any other kind of end users. This interface must, at the very least, allow visualizing the network elements on a map, also granting the ability to make queries over these elements in an intuitive and responsive way, while respecting the usual quality principles of any user-oriented software of this kind.
	
	\section{Contributions}
	As the two contexts from Section~\ref{sec:pd}~lead to different ways of structuring and querying the information, it is natural to expect at least two different representations, one for each context. For this reason, in this work we have applied some of compact data structures to design novel representations that are able to handle massive collections of data related to user transportation habits. Our proposed representation cover both contexts, as well as offer a fair trade-off for different query needs, while at the same time ensuring that our proposals can be implemented in a real world scenario, for which we evaluate the performance of our representations with realistic query cases over real datasets\footnote{When needed, the real data was augmented or mixed with synthetic information}.
	
	Furthermore, as a proof of the practicability of our approach, we have developed a user interface that is based on our representations, and allows a user to perform queries through a \gls{gis} web interface. Unlike traditional \gls{gis} interfaces, ours is focused on offering convenient methods to query past user trajectories by network elements instead of purely spatial relationships, and achieves far superior performance when compared to systems backed by traditional database systems.
	
	In conclusion, we present an end-to-end platform around representations based on compact data structures to process, store, query and visualize mined public transportation usage data. To our knowledge, this is the first work to accomplish building such integrated platform, although other works exist that contemplate the use of compact data structures for trajectories or moving objects (see Section~\ref{sec:ti}).
	
	\section{Outline}
	This work is structured as follows...
	
\chapter{State of the art in trajectory extraction and representation}
    This chapter is dedicated to provide a context to our contributions with a literature review of tangential works. We start by discussing methods of collecting useful trajectory data, followed by a review of mobile objects and models for the trajectories they generate, as well as types of queries that are often found in mobile objects research. Finally, we look into the most relevant works in trajectory indexing, which contrast with our contributions as the later are based on auto-indexed representations, and are focused on problems specific to the study of transportation demand and travel patterns on transportation networks.

	\section{Trajectory extraction}
	\label{sec:dm}
	In order to make significant conclusions about the travel patterns, it is essential to be able to collect a large enough collection of trips to be representative enough of the overall usage within a time span. For this problem, crowd-sourcing can be a viable approach to record the trajectories of public transportation users, as done in \cite{zimmerman2011field}, where the users were rewarded with real information on the bus location, estimation of arrival time and fullness in exchange of recording the GPS trace on their own bus trips.
	
	Currently there are several known techniques that would allow to collect data regarding users' trips over a public transportation network. Numerous works exist where those trajectories are mined from the transactions of smart cards \cite{bhaskar2015passenger,wang2014aggregated}. This can be complemented with information derived from GPS devices, as shown in \cite{ma2014development}. Alternatively, reliable trajectories may be extracted relying on positioning obtained from cellular networks, as proven by \cite{liu2017exploring}.

    Because smart card methods usually provide only information about boarding stops, there are works that study the challenge of inferring alighting stops from passengers \cite{wang2011review}. In addition, the authors of \cite{tao2014exploring} have specifically tackled the challenge of reconstructing full trajectories, accounting for trip-chaining, by using data obtained from smart cards. Furthermore, in \cite{alsger2016validating} it is also proven that not only the alighting stops, but also the (last) destination stop of a trip can be estimated from boarding data gathered by a smart card, within a reasonable accuracy, given that a transportation network user typically makes a return trip at another time of the day, as happens often with people that commute from their homes to work and back. We find these methods particularly interesting, as a significant portion of the query patterns we propose in order to analyze passenger movements rely on knowing about line switches (trip-chaining) and the ultimate destination of a trajectory.
    
    However, there is little research on methods for exploitation of this extracted information, in order to analyze and improve the efficiency of a transportation network, which constitutes the scope of our work. This summarized review proves that, although we were not able to access real data from a public transportation company for this work, such curated information about users' trips can indeed be obtained and used for our proposed representations.
	
	\section{Models of trajectory and types of queries}
    A good place to begin searching for practical models of trajectory representation is the vast amount of work on designing data models for moving objects~\cite{DBLP:conf/ssdbm/WolfsonXCJ98,DBLP:conf/icde/SistlaWCD97,DBLP:journals/tods/GutingBEJLSV00,DBLP:conf/chorochronos/GutingBEJLNSV03,DBLP:journals/geoinformatica/Spaccapietra01,DBLP:conf/sigmod/ForlizziGNS00,DBLP:journals/geoinformatica/ErwigGSV99,DBLP:books/mk/GutingS2005}. Basically, a moving object data model represents the continuous change of the location of an object over time, this way defining a trajectory.
    
    The moving objects can be seen as a big data problem, where solutions may typically differ in the representation of location, contextual or environmental information where the movement takes place, the time dimension, which can be continuous or discrete, and the level of abstraction or granularity on which the trajectories are described~\cite{DBLP:journals/sigspatial/DamianiIGV15}. A common classification of trajectories distinguishes free from network-based trajectories.  \textit{Free trajectories} or Euclidean trajectories are a sequence of GPS points represented by an ad-hoc data type of moving points~\cite{DBLP:conf/ssdbm/WolfsonXCJ98,DBLP:conf/icde/SistlaWCD97,DBLP:journals/tods/GutingBEJLSV00}. \textit{Network constrained} trajectories are a temporal ordered sequence of locations on networks. This trajectory model includes a data type for representing  networks and  for representing the relative location of static and moving  points on the network~\cite{DBLP:journals/vldb/GutingAD06}. When we want to represent trajectories over an urban street network, it is often useful to deal with \textit{network-matched trajectories}, as this will allow to represent large collections trajectories more efficiently. The process of obtaining these network-matched trajectories from GPS points is called \textit{map-matching} \cite{brakatsoulas2005map}. This process can also be done online, as recently shown in~\cite{DBLP:journals/tits/Ding0GL15}, where all the processing is done in the server, eliminating the need of any map or network representation at the moving object side.
    
    The definition of trajectories at an abstract level must be materialized in an internal representation with access methods for query processing. An early and broad classification of spatial-temporal queries for \textit{historical positions} of moving objects \cite{DBLP:conf/vldb/PfoserJT00} identifies coordinate- and trajectory-based queries. Coordinate-based queries include the well-known  {\it time-slice}, {\it time-interval} and \textit{nearest-neighbor queries}. Examples are \textit{find objects or trajectories in a region at a  particular time instant or during some time interval}. Another important example of coordinate-based queries is \textit{find the k-closest objects with respect to a given point at a given time instant}. Trajectory-based queries  involve topology of trajectories (e.g., overlap and disjoint) and information (e.g., speed, area, and heading) that can be derived from the combination of time and space. An example of such queries would be  \textit{find objects or trajectories that satisfy a spatial predicate (eg., leave or enter a region)  at a particular time instant or time interval}. There also exist combined queries addressing information of particular objects: \textit{Where was object X at a particular time instant or time interval}. In all previous queries, the results are individual trajectories that satisfy the query constraints.
    
    %When dealing with large datasets of trajectories, and due to privacy issues, the individual trajectory cannot be revealed, then anonymized and aggregated trajectories are of concern.  
    In many applications, aggregated trajectories must be analyzed in the collection, as an individual trajectory does not represent any useful information.
    In this context, we can  further distinguish range- from trajectory-based queries. Range queries impose constraints in terms of a spatial location  and temporal interval.  Examples of these queries are  to retrieve the number of distinct trajectories  that intersect a spatial region or spatial location (stop) at a given time instant or time interval, retrieve the number of distinct trajectories that start at a particular location (stop) or in a region and/or end in another particular location of region, retrieve the number of trajectories that follow a path, 
     and retrieve the  top-k locations (stops) or regions  with the larger number of  trajectories that  intersect  at a given time instant or time interval. Trajectory-based queries require not only to use the spatio-temporal points of trajectories  but also the sequence of these points. Examples of such queries are  to find the number of trajectories that are heading (not necessarily ending at) to a spatial location during a time interval, find the destination of trajectories that are passing through a region during a time interval, find the number of starting locations of  trajectories that go or pass through a region during a time interval.
	
	\section{Trajectory indexing}
	\label{sec:ti}
	Literature on spatial trajectory indexing can be categorized by the nature of the trajectories: they can be either constrained to a network or in free space (often called moving objects). While there are well-known queries for indexes that work on moving objects in free space \cite{DBLP:conf/vldb/PfoserJT00}, the network constrained trajectory indexes cover more diverse querying needs, as different networks involve different kinds of challenges (as in vehicular road network vs public transportation network), and also because the intended application may vary (analyzing trip-chaining patterns vs number of passengers within a time window). A comprehensive review on indexing methods can be found in \cite[Chapter 4]{DBLP:books/sp/PelekisT14}, to which we shall expand in the rest of this section to mention the most notable indexes and some new developments.
	
	\subsection{Free trajectory indexing}
	Several adaptations of the {\em R-Tree} \cite{DBLP:conf/sigmod/Guttman84} are widely used for the indexing of moving objects. The most common approach is to integrate the temporal dimension in the R-Tree itself, as found in the {\em STR-Tree} and the {\em TB-Tree} from \cite{DBLP:conf/vldb/PfoserJT00}.
    Another common approach is to compliment the R-Tree with another similar structure, as has been done for the {\em MV3R-tree}~\cite{DBLP:conf/vldb/PapadiasT01},
    where an Historical {\em R-Tree}~\cite{nascimento1998towards} to partition on the temporal dimension.
    
    Generally, even for very large collections of trajectories, the spatial dimensions are more bounded than the temporal dimension, which can grow indefinitely. For this reason, even for free trajectories, temporal dimension is generally more selective than spatial dimensions. This observation was heavily exploited in the subsequent works, such as {\em SETI} from \cite{chakka2003indexing}, where the space is partitioned statically, while trajectories are indexed by their temporal dimension using a one dimensional R-Tree, allowing it to grow dynamically.
    
    Recently a framework based on Apache Spark was developed called {\em UlTraMan}~ \cite{ding2018ultraman}, that supports different kinds of partitioning schemes for large collections of trajectories to answer range, kNN or aggregation queries, allowing to repartition the dataset to maximize the query time efficiency for a given query type. Although UlTraMan has been tested over network constrained trajectories, it does not appear to be exploiting network information in any way, hence its inclusion in this category.
    
    In the field of compact data structures, an index called {\em GraCT}~\cite{brisaboa2019gract} has been developed, based snapshots at regular time intervals using {\em k$^2$-Trees}~\cite{brisaboa2009k} and movement logs for individual trajectories to which grammar compression is applied with {\em RePair}~\cite{larsson2000off}. Because of this, GraCT is a self-indexed compact representation that supports spatio-temporal range and nearest-neighbor queries, as well as allowing for direct access to the trajectory information.
	
	\subsection{Network constrained trajectory indexing}
	There are also numerous approaches that use R-Tree based indexes for trajectories that are constrained to an underlying network, aiming to decrease the redundancy in the representation by separating the representation into levels. Examples of such indexes include the {\em FNR-Tree}~\cite{DBLP:conf/ssd/Frentzos03}, where the network elements are indexed with a 2D R-Tree and 1D R-Trees to index time intervals of moving objects along the edges of the network. Some of the limitations of the FNR-Tree are addressed in \cite{DBLP:journals/geoinformatica/AlmeidaG05}, where the authors propose the {\em MON-Tree}, where the moving objects are indexes in two dimensional R-Trees (the dimensions being edge position vs time). More recent alternatives, such as the {\em TMN-Tree}~\cite{chang2010tmn}, integrate {\em B$^+$-Trees}, which have proven to be more space and time efficient for indexing the temporal dimension. Alternatively, in \cite{rivera2018faster} a compact representation of time intervals is proposed using two bitvectors, that can be combined with these R-Tree based indexes to increase the efficiency for temporal filtering. Refer to \cite{john2017performance} for a quick comparison of these R-Tree based indexes.

    As a competitive alternative to these R-Tree based indexes, {\em PARINET}~\cite{DBLP:journals/vldb/PopaZOBV11}, builds spatial partitions from the trajectories based on their distribution and network topology, and uses a B$^+$-Tree to index the trajectories in each partition by time intervals. Although candidate trajectories must be filtered in memory during queries, PARINET is highly efficient in practice as its partitioning strategy minimizes the number of disk accesses needed.
    %The same ideas were used in {\em TRIFL}~\cite{that2015trifl}, where the cost model is adapted for flash storage.
    
    Another relevant representation is described in \cite{DBLP:conf/gis/KroghPTT14}. Their proposed index, {\em NETTRA}, was designed to efficiently solve a specific kind of query called {\em Strict Path Queries (SPQ)}, built on a traditional RDBMS with $B^+$-Tree indexes. Another distinctive feature of NETTRA is its treatment of network constrained trajectories as textual information, which allows to apply string matching techniques such as fingerprinting functions to determine what trajectories have similar paths on their traversed edges. This close equivalence between trajectories and strings has been further exploited by Geodabs~\cite{chapuis2018geodabs}, where both the spatial distribution and sequence information are taken into account for finding trajectories by similarity with fingerprinting. These text-based approaches are sometimes tangled with works on the topic of semantic trajectories such as \cite{al2017semantictraj}.
    
    %For vehicles we also have this \cite{cai2018vector} and \cite{lovell2018lossless}.
    
    A recent compact data structure named {\em CiNCT} has been proposed in \cite{koide2018cinct}, where trajectories are encoded into a string, that is used to build an FM-index \cite{DBLP:conf/focs/FerraginaM00} with a Huffman-shaped Wavelet Tree \cite{ferragina2009compressed}. To further save space, the string is constructed with relative movement labels instead of absolute edges, with an auxiliary structure that represents a network graph built from the input trajectories themselves. While this structure excels at pattern-matching and path extraction in vehicular networks (such as the streets of a city), it cannot be applied to our problems in public transportation networks, where network demand and aggregated travel patterns have to be analyzed, while finding out which trajectories traversed on a specific path of sequential street segments does not, in itself, provide us much relevant information.
	
	
\part{Compact representation of trajectories over transportation networks}
\chapter{Previous concepts}
	This chapter may serve as an introduction to the compact data structures used in our proposed representations, and it should give a sufficient understanding of the underlying concepts that we will be working with for the rest of this part. For a more in-depth guide on compact data structures, the reader may refer to \cite{Nav16}.
	%, where they are introduced from basic information theory concepts such as entropy.
	
	A reader who is already familiar with compact data structures is still encouraged to read the Section~\ref{sec:sat}, where the \gls{sat} is introduced, which is initially unrelated to compact data structures, and also the Section~\ref{sec:wt}, where we discuss some less known variants and operations of the \gls{wt}, that we make use of in our contributions.
	
	\section{Summed Area Table}
	\label{sec:sat}
	The \gls{sat} was first introduced in computer graphics \cite{crow1984summed} to speed up the mipmapping process, where given a texture image represented as bidimensional matrices of numbers (usually three matrices of integers, one for each color channel) we are interested in finding the average color of any arbitrary rectangle within the image. This operation is most often used to reduce the rendering time for distant polygons where a pixel on the target screen may correspond to several texture pixels (texels), and also for anisotropic filtering, in order to improve the visual quality of polygons that are projected in an oblique angle.

    With the most direct representation of a matrix as an array of values, we are required to compute the average value of a rectangle $(a,b),(a+h,b+w)$ as:
    
    \[
    \overline{M}_{a..a+h,b..b+w}~\leftarrow~
    \frac{\displaystyle\sum^h_{i=0}\displaystyle\sum^w_{j=0}M_{i+a,j+b}}
    {(h+1)(w+1)}
    \]
    
    Note that the summation has a time complexity of $O(hw)$, which would make this operation quite expensive for real time rendering applications. In order to improve the complexity of these calculations, the \gls{sat} precomputes the summations of $M$ in a matrix $I$, of the same size, where $I_{a,b}~\leftarrow~\displaystyle\sum^a_{i=0}\displaystyle\sum^b_{j=0}M_{i,j}$. That is, each cell of $I$ is the sum of the values within rectangle spanning from the origin of the matrix to the position of the cell. An example of a \gls{sat} can be found in the Figure~\ref{fig:sat}.
    
    \begin{figure}[ht]
		\begin{center}
			{\includegraphics[width=0.8\textwidth]{figures/example_sat.eps}}
		\end{center}
		\caption{An example of a \acrlong{sat} (right) built over a matrix (left).}
		\label{fig:sat}
	\end{figure}
    
    Having $I$, we can compute the average value of a rectangle in $O(1)$ operations as:
    
    \[
    \overline{M}_{a..a+h,b..b+w}~\leftarrow~
    \frac{I_{a+h,b+w} - I_{a+h,b-1} - I_{a-1,b+w} + I_{a-1,b-1}}
    {(h+1)(w+1)}
    \]
    
    In our example from Figure~\ref{fig:sat}, to calculate the sum of the delimited $3x3$ region in the matrix, we simply operate over the four terms in \textbf{bold} from the \gls{sat}, obtaining
    $\displaystyle\sum^4_{i=2}\displaystyle\sum^4_{j=2}M_{i,j}~=~I_{4,4}-I_{4,1}-I_{1,4}+I_{1,1}~=~84-27-18+8~=~47$.
    
    While with this representation we do not need to keep the original matrix\footnote{As accessing a single cell can be viewed as a special case of the computation of an average where $h=0,w=0$.}, the improved computational efficiency comes at the expense of having to represent larger numbers than the original values.
	
	\section{Entropy coding}
	Given an information source (such as a text) that provides symbols from an alphabet $[1..\sigma]$ with a probability of $0 \leq p_i \leq 1$ for each symbol, where $\displaystyle\sum_ip_i=1$, the goal of an entropy coder is to exploit these probabilities in order to achieve compression by assigning shorter codes to the most frequent symbols, and longer to the less frequent ones. In the work that is considered as the foundation of information theory \cite{shannon1948mathematical}, Claude Shannon defined a concept called \textit{entropy}, which is closely related to the probabilities we are discussing, and used it to prove that the when encoding the symbols in binary, the optimal length in bits for each code is of $l_i = \frac{1}{\log_2p_i} = -\log_2p_i$ bits, and the entropy of an information source $S$ calculated as $H_0(S) = -\displaystyle\sum^\sigma_i p_il_i = -\displaystyle\sum^\sigma_i p_i\log_2p_i$.
	
	As this compression technique relies on using variable-length codes, it is necessary that the codes are unambiguous: there can be no two codes $C_i, C_j$ that, when concatenated, can be interpreted as another code 
	% esto esta mal porque no contempla el caso de concatenar tres o mas codigos ambiguos
	%($C_iC_j \neq C_k, \forall i,j,k \in [1..\sigma]$)
	. Additionally, it is computationally very useful for those codes to also be prefix-free, meaning that there can be no code that is the prefix part of another ($C_i \neq C_j0^a1^b,~\forall i,j \in [1..\sigma], i\neq j, a,b \in [0..\infty)$), as this will allow us to unambiguously interpret the symbol right after the bits of $C_i$ are read, without having to determine if it could be the prefix part of some other longer code $C_j$.
	
	The Huffman coding, introduced in \cite{huffman1952method}, is a coding algorithm that produces prefix-free and optimal\footnote{That is, with lengths as close to $-\log_2p_i$ as possible with a whole number of bits per symbol.} codes based on the frequencies of each symbol. The ideas of the Huffman coding have been widely implemented in numerous compression algorithms and codecs since its inception, where the most notable examples are DEFLATE (PKZIP, GZIP), JPEG and MPEG.
	
	One less known variation of the Huffman codes are the Hu-Tucker codes \cite{hu1971optimal}, which aim to provide codes that preserve the same lexical order as the original symbols, meaning that for any two symbols $s_i,s_j$, it holds that $s_i \prec s_j \iff C_i \prec C_j$. This comes at the expense of at most one extra bit per code over Huffman on average\footnote{Being $L_h$ and $L_{ht}$ the average codeword 
	length of Huffman coding and Hu-Tucker codes for $S$ respectively, it holds: $H_0(S) \leq L_h \leq H_0(S)+1$ and $H_0(S) \leq L_{ht} \leq H_0+2(S)$
	(see \cite{Cover:2006:EIT:1146355} (pages 122-123), or \cite{HORIBE1977148, GilbertandMore1959}).}.
	
	\section{Bitvectors}
	\label{sec:bit}
	A great amount of works in compact data structures involves the use of bitvectors, both compressed and uncompressed. A bitvector $B[1..n]$ is a sequence of $n$ bits, for which the following operations are expected to be supported:

    \begin{itemize}
        \item $\rank_1(B,i)$ is the number of set bits in $B[1..i]$. Alternatively, $\rank_0(B,i)~\leftarrow~i - \rank_1(B,i)$. Consequently, it also holds that the bit from the position $i$ can be retrieved as $B[i] = \rank_1(B,i) - \rank_1(B,i-1)$.
        \item $\select_1(B,i)$ is the position in $[1..n]$ where the $i$th 1 occurs. Therefore, $\rank_1(B,\select_1(B,i)) = i$. An equivalent version for 0 bits may be defined as $\select_1(B,i)$, although, unlike with $\rank_0$, there does not exist a direct way of obtaining it from the previously defined operations.
    \end{itemize}
    
    \begin{example}
        Given a bitvector $B = 011001$, it holds that $\rank_1(B,1) = 0$, $\rank_1(B,2) = 1$, $\rank_1(B,3) = 2, \rank_1(B,4) = 2$. Furthermore, $B[3] = \rank_1(B,3) - \rank_1(B,2) = 1$ and $\rank_0(B,3) = 3 - \rank_1(B,3) = 1$.
        
        We can also say that $\select_1(B,2) = 3$ and $\select_1(B,3) = 6$, thus holding that $\rank_1(B,\select_1(B,2)) = \rank_1(B,3) = 2$ and $\rank_1(B,\select_1(B,3)) = \rank_1(B,6) = 3$. Additionally, $\select_0(B,2) = 4$ as $\rank_0(B,\select_0(B,2)) = \rank_0(B,4) = 2$.
        \qed
    \end{example}
    
    All these operations can be supported in $O(1)$ time with $o(n)$ extra bits \cite{Jac89,Mun96}. 
    Additionally, there exist several techniques for compressing these bitvectors based on their arrangement although several techniques exist for compressing bitvectors depending on their statistical properties. In this work we will use a representation that excels in efficiently solving $\select_1$ operations for sparse bitvectors (with a low number of set bits in proportion to the bitvector size) introduced in \cite{okanohara2007practical}, and also another representation that works particularly well with non uniformly distributed bitvectors, thus exploiting their entropy to require only $nH_0(B) + o(n)$ bits\footnote{Being $n_1$ the number of set bits in $B$ and $n_0 = n - n_1$, then $H_0(B) = \dfrac{n_1\log\dfrac{n}{n_1} + n_0\log\dfrac{n}{n_0}}{n} \leq 1$.} \cite{Raman:2002:SID:545381.545411}.
	
	\section{Wavelet Tree and Wavelet Matrix}
	\label{sec:wt}
	When working with a sequence $S[1..n]$ over an alphabet $[1..\sigma]$, we can extend the definitions of $\rank$ and $\select$ from the Section~\ref{sec:bit} to work over an any symbol $a \in [1..\sigma]$ instead of bits, resulting in the following operations:
	
	\begin{itemize}
	    \item $\rank_a(S,i)$ is the number of occurrences of the symbol $a$ in $S[1..i]$.
	    \item $\select_a(S,i)$ is the position in $[1..n]$ where the $i$th $a$ occurs.
	\end{itemize}
	
    The \gls{wt} \cite{WT03} represents $S$ with a balanced binary tree, with $\sigma$ leaves, one for each symbol. Every internal node $v$ represents a the range of symbols $[\alpha_v..\omega_v] \subseteq [1..\sigma]$ in the same order as they appear in $S$, where the root node corresponds to all the $n$ symbols from the alphabet $[1..\sigma]$ appearing in $S$. Its left child $v_l$ will only represent the $n_l$ symbols that fall in the range $[1..\dfrac{\sigma}{2})$, preserving the order that they had in $v_0$, while the right child will represent the other $n_r$ symbols from $[\dfrac{\sigma}{2}..\sigma]$, holding that $n_l+n_r=n$. This is built recursively until a leaf $v_a$ is reached, with will correspond to only one symbol $a \in [1..\sigma]$, with $n_a = \rank_a(S,n)$ times. An example \gls{wt} can be found in Figure~\ref{fig:wt}.
    
    \begin{figure}[ht]
		\begin{center}
			{\includegraphics[width=0.65\textwidth]{figures/wt1.eps}}
		\end{center}
		\caption{An example \acrlong{wt} of four levels.}
		\label{fig:wt}
	\end{figure}
    
    For each node $v$, these symbols from the alphabet $[\alpha_v..\omega_v]$ are represented implicitly using a bitvector $B_v[1..n_v]$, where $B[i] = 0$ when the symbol $a$ represented in the position $i$ should belong to the left child ($a < \dfrac{\alpha_v + \omega_v}{2}$), while $B[i] = 1$ means it should belong to the right child ($a \geq \dfrac{\alpha_v + \omega_v}{2}$). By making use of $\rank$ and $\select$ operations over these bitvectors, we are able to recover the value of any $S[i]$, and also answer $\rank_a$ and $\select_a$ for any $a \in [1..\sigma]$ in $O(\log\sigma)$ without the need of storing the original sequence. As there are $n$ bits per level and $\log\sigma$ internal levels (the nodes from the leaf level do not have bitvectors), we could represent every bitvector in $n\log\sigma$ bits, which is equivalent to the space it would take to represent $S$ as an array of fixed length integers\footnote{When $\sigma$ is not a power of two, $\log\sigma$ would need to be rounded up for fixed length integers, while for the \gls{wt} there will be some leaves at level $h-1$, being $h$ the height of the tree, and its total size will depend on the frequency of those symbols ($\lfloor n\log\sigma\rfloor < \sum_i n_i < \rceil n\log\sigma\rceil$.}). However, we also need some auxiliary structures for $\rank_1$ and $\select_1$, which will require $o(n\log\sigma)$ bits and also store a pointer for every one of the $2\sigma-1$ nodes. Therefore, the total size of this representation amounts to $n\log\sigma + o(n\log\sigma) + O(\sigma\log n)$.
    
    In order to access the value of $S[i]$, we must start by looking into $B_v[i]$ from the root node. If $B_v[i]=0$, we traverse to the position $B_{v_0}[\rank_0(B_v,i)]$ of the bitvector of the left child. Conversely, when $B_v[i]=1$, we traverse to the bitvector of the right child at $B_{v_1}[\rank_1(B_v,i)]$. In both cases, we recurse until a leaf is reached, which will unambiguously correspond to a symbol $a$, thus we determine that $B_v[i]=a$.
    
    \begin{example} \label{exp:wtaccess}
    In the \gls{wt} from Figure~\ref{fig:wt}, if we wanted to retrieve the value of $S[2]$, we would start by looking into the bit $B_v[2]=0$, meaning that the we have to traverse to the node $v_0$ and look into the bit $B_{v_0}[\rank_0(B_v,2)] = B_{v_0}[2] = 1$, leading us to the node $v_{01}$ at $B_{v_{01}}[\rank_1(B_{v_0},2)] = B_{v_{01}}[2] = 0$. The left node is a leaf node belonging to the symbol $2$, so $S[2]=2$ (namely, the first occurrence of $2$ in $S$, as $\rank_0(B_{v_{01}}, 2) = 1$).
    \qed
    \end{example}
    
    We can also solve $\rank_a$ by traversing the tree from top to bottom with the bitvector $\rank$ operation: knowing that the binary representation (and thus also the path in the \gls{wt}) of a symbol will allow us to use $\rank_1$ or $\rank_0$ in each level $i$ according to the $i$th bit of our code. In the Example~\ref{exp:wtaccess}, knowing that the binary representation of $2$ is $010$, we can calculate $\rank_2(S,2)$ (or any other position) following the same order of operations: a $\rank_0$, a $\rank_1$ and one final $\rank_0$ to determine the position of the leaf node, which will give away $\rank_2$. It is also possible to calculate $\select_a(S,i)$ with a bottom to top traversal of the tree, by starting at the $i$th position from the leaf belonging to $a$, and applying $\select_0$ and $\select_1$ on the bitvectors of the parent nodes, following the reversed binary code of $a$. Eventually, a position $S[i]=a$ will be reached such that it will contain the $i$th occurrence of $a$ in $S$.
    
    A more complex operation that we have found very useful in our work in is the $\cnt_{a,b}(S,i,j)$, first described in \cite{gagie2012new}, which counts the number of occurrences of symbols in $[a..b]$ within $S[i..j]$. While it is equivalent to $\displaystyle\sum^b_{k=a}\rank_k(S,j) - \rank_k(S,i)$, it can be solved more efficiently by doing two simultaneous top to bottom traversals, as described for $\rank_a$. Starting at the root node $v$ we calculate $\rank_0(B_v,i)$ and $\rank_0(B_v,j)$ to find out the limits in the left node for the codes within $[a..b]$ that start with 0, and also $\rank_1(B_v,i)$ and $\rank_1(B_v,j)$ for those codes starting by 1. If all of the codes in $[a..b]$ start with either a zero or a one, we will only compute the corresponding $\rank$. After that, we recurse for each node, where on the left $i~\leftarrow~\rank_0(B_v,i)$, $j~\leftarrow~\rank_0(B_v,j)$ and we only consider the range of symbols $[a..b']$ that can be represented by that node ($b' \leq \omega_{v_0})$). The same is true for the recursion on the right, where $i~\leftarrow~\rank_1(B_v,i)$, $j~\leftarrow~\rank_1(B_v,j)$ and $\alpha_{v_1} \leq a'$. Therefore, 
    \begin{align*}
    \cnt_{a,b}(v,i,j) = &\cnt_{a,b'}(v_0,\rank_0(B_v,i),\rank_0(B_v,j))\\
    &+~\cnt_{a',b}(v_1,\rank_1(B_v,i),\rank_1(B_v,j))
    \end{align*}
    , recursively. The recursion on each node $v$ stops when $a \leq \alpha_v$ and $\omega_v \leq b$, in which case the count for that node is reported as $j-i+1$. Finally, all the counts are summed and the total amount of occurrences is obtained. While it may look as if the worst case would imply traversing every of the $\sigma$ internal nodes, it is avoided by stopping the recursion when $a \leq \alpha_v$ and $\omega_v \leq b$, thus requiring us to visit only $O(\log\sigma)$ nodes\footnote{In fact, the best case is $cnt_{1,\sigma}(S,i,j) = j-i+1$, which is solved without traversing at all!}. In the \gls{wt} from Figure~\ref{fig:wt}, we have marked the considered ranges for solving $\cnt_{3,3}(S,5,10)$. Additionally, when the subsequence $S[i..j]$ is sorted, we can define $[l..r]~\leftarrow~\cnt^{LR}_{a,b}(S,i,j)$, which returns the upper and lower limits $S[l..r]$ of the occurrences of the symbols $[a..b]$. Naturally, $S[l..r] \subseteq S[i..j]$.
    
    \subsection{Hu-Tucker Wavelet Tree}
    A straightforward way of reducing the size of a \gls{wt} is to use compressed bitvectors, as discussed in \cite{CNspire08.1}, allowing to represent a \gls{wt} in $nH_0(S) + o(n\log\sigma) + O(\sigma\log n)$ bits \cite{WT03}. There is, however, a different approach to achieve similar space requirements is to use a prefix-free variable-length encoding for the symbols.
    For example, Huffman code \cite{huffman1952method} can be used to build a
    Huffman-Shaped \gls{wt} \cite{ferragina2009compressed}, where the tree is not balanced
    anymore, as level of each leaf $v_a$ will be the number of bits for the Huffman code of $a$, which will depend on the frequency of $a$ in $S$. The size reduces to $n(H_0(S)+1)+ o(n(H_0(S)+1)) +  O(\sigma \log n)$\footnote{$O(\sigma \log n)$ term 
    includes both the tree pointers and the size of the Huffman model.}, while average time becomes
    $O(H_0(S))$ for $\rank_a$, and $\select_a$  (the worst-case time is still $O(\log\sigma)$ 
    \cite{Barbay:2013:CPA:2562345.2562626}). By using compressed
    bitvectors \cite{CNspire08.1} space can be even further reduced to $nH_0(S) + o(n(H_0(S)+1)) +  O(\sigma \log n)$.
    Unfortunately, the Huffman codes (including \textit{canonical Huffman}) assigned to
    lexicographically adjacent symbols do not maintain that lexicographic order, and it is not possible to have a $O(\log\sigma)$ bound for $\cnt_{a,b}(S,i,j)$ anymore.
	
	In order to support $\cnt_{a,b}(S,i,j)$ more efficiently, Hu-Tucker codes \cite{hu1971optimal} can be used instead. While the compression achieved by a \gls{htwt} \cite{barbay2009compressed} degreades slightly with respect to using Huffman coding, yielding a bound of $n(H_0(S)+2) + o(n(H_0(S)+1)) +  O(\sigma \log n)$\footnote{This can be reduced to  $nH_0(S) + o(n(H_0(S)+1)) +  O(\sigma \log n)$ by using compressed bitvectors as well.}, the codes for adjacent symbols are lexicographically contiguous. Therefore, we can guarantee a bound of $O(\log\sigma)$ for $\cnt_{a,b}(S,i,j)$ again. An example of a \gls{htwt} in practice can be found in the Figure~\ref{fig:wtwm}.
	
	\subsection{Wavelet Matrix}
	\label{sec:wm}
	For large alphabets, the size of the \gls{wt} is affected by the term $ O(\sigma \log n)$. A {pointerless}
    \gls{wt} \cite{CNspire08.1} permits to remove\footnote{In a pointerless Huffman-shaped \gls{wt}  a
    term $O(\sigma \log\log n)$ still remains due to the need of storing the canonical Huffman model.} 
    that term by concatenating all the bitvectors level-wise 
    and computing the values of the pointers during the \gls{wt} traversals. 
    The operations on a pointerless \gls{wt} have the same time complexity but become slower in practice. 
    
    By reorganizing the nodes in each level of a pointerless \gls{wt}, the \gls{wm} \cite{CNO15} obtains the  same space requirements, yet its performance is very close 
    to that of the regular \gls{wt} with pointers. Figure~\ref{fig:wm} contains an example of a \gls{wm}, representing the same sequence as in Figure~\ref{fig:wt}.
    
    \begin{figure}[ht]
	\begin{center}
		{\includegraphics[width=0.65\textwidth]{figures/wm1.eps}}
	\end{center}
	\caption{An example \acrlong{wm} of three levels. A conceptual fourth level was omitted since it does not contain a bitvector.}
	\label{fig:wm}
	\end{figure}
    
    As in the \gls{wt}, the $i$-th level stores the $i$-th bits of the encoded symbols. 
    A single bitvector $B_i$ is kept for each level. In the first level, $B_1$ stores the
    $1$-st bit of the encoding of the symbols in the order of the original sequence $S$.
    From there on, at level $i$, symbols are reordered according to the $(i-1)$-th bit of their encoding; 
    that is, according to the bit they had in the previous level.
    Those symbols whose encoding had a zero at position $i-1$ must be arranged before those that
    had a one. After that, the relative order from the previous level is maintained. That is, if 
    a symbol $a$ occurred before other symbol $b$, and the $(i-1)$-th bit of their encoding
    coincides, then $a$ will precede $b$ at level $i$. %Note that, following this rule,
    %the symbols in the last level shall be ordered by their reversed bit encoding.
    
    If we simply keep track of the number of zeros at each level $z_l\leftarrow \rank_0(B_l,n)$, we can easily see that the symbol with the $k$-th zero
    at level $i-1$ is mapped at position $k$ within $B_i$, whereas the symbol with the $j$-th one at level $i-1$ is 
    mapped at position $z_l +j$ within $B_i$. This avoids the need for pointers, enabling to retain
    the same time complexity of the \gls{wt} operations, including $\cnt_{a,b}(S,i,j)$. For 
    implementation details see \cite{CNO15,ordonez2015statistical}. 
    
    \begin{example}
    To find out the symbol at $S[8]$, we start by observing that $B_1[8]=0$ and $\rank_0(B_1,8)=5$. We move to the next level where we check position $5$; we see that $B_2[5]=1$ and $\rank_1(B_2,5)=3$. We move to next level and check position $3+z_2 = 3+5 = 8$,
    where we finally see $B_3[8]=1$. Therefore, we have decoded the bits $\mathbf{011}$ that correspond to the symbol $S[8] = 3$.
    \qed
    \end{example}
    
    To reduce the space needs of \gls{wm} we could use compressed bitvectors as for \gls{wt}. Yet, 
    compressing the \gls{wm} by giving it either a Huffman or Hu-Tucker shape is not possible as the reordering of the \gls{wm} would lead to the existence of %holes in the structure 
    gaps in the bitvectors 
    that would ruin the process of 
    tracking symbols during traversals. To overcome this issue, an optimal Huffman-based coding was 
    specifically developed for wavelet matrices \cite{CNO15, Farina2016}. This allows to obtain space
    similar to the one a pointerless Huffman-shaped \gls{wt} but with faster $\rank_a$ and $\select_a$ operations.
    Unfortunately, since the encodings of consecutive symbols do not keep the same order, $\cnt_{a,b}(S,i,j)$ is no longer supported in $O(\log\sigma)$ time.
    %and computing $\rank_a(S,j)-rank_c(S,i)+1$ is required for each $c$ in $[\alpha,\beta]$.
	
	\section{Compressed Suffix Array}
	\label{sec:csa}
	Given a sequence $S[1..n]$ built over an alphabet $\Sigma$ of length
    $\sigma$, the {\em suffix array} $A[1..n]$ is built over $S$ \cite{MM93}
    as a permutation of the positions $i \in [1..n]$ of all the suffixes $S[i..n]$, so that
    $S[A[i]..n] \prec S[A[i+1]..n]$ for all $1 \le i < n$
    %, being $\prec$ the lexicographic ordering. 
    Because $A$ contains all the suffixes of $S$ in lexicographic order,
    we can use this structure to search for any pattern $P[1..m] \in S$ in time
    $O(m \log n)$ by simply performing binary searches for the range $A[l..r]$ that
    contains pointers to all the positions in $S$ where $P$ occurs.
    %For the construction of the $A$ a linear time construction
    %algorithm such as the SA-IS~\cite{nong2011two} could be used.
    %which is based on induction sorting.
    We can find an example of an suffix array $A$ in the Figure~\ref{fig:csa}. Any pattern $P[1..m] \in S$ (such as $ana$) can be delimited by a range $A[l..r]$ (for $ana$ it is $A[3..4]$), where the limits $l$ and $r$ can be found with binary searches due to the suffixes being sorted.
    
    \begin{figure}[ht]
		\begin{center}
			{\includegraphics[width=0.5\textwidth]{figures/csa.eps}}
		\end{center}
		\caption{All the structures involved in constructing a \acrlong{csa} over the sequence $S = banana\$$. Note that $S$ and $A$ do not need to be stored.}
		\label{fig:csa}
	\end{figure}
    
    A straightforward enhancement to avoid storing the original string $S$ is to set up a vocabulary array $V[1..\sigma']$, with all the different symbols from $\Sigma$ appearing in $S$\footnote{$\sigma' \leq \sigma)$, since some of the symbols from $\Sigma$ may never appear in $S$.}, and a bitvector $D[1..n]$ aligned to $A$ so that $D[1]=1$ and $D[i]=1~\iff~S[A[i-1]] \neq S[A[i]]$ for all the other $i \in [2..n]$. This means that $D$ marks with a $1$ the beginning of a range of suffixes pointed from $A$ such that the first symbol of those suffixes coincides. With $D$, keeping $S$ is not longer needed since $S[A[i]] = V[\rank_1(D,i)]$.
    
    We also replace $A$ as described in Sadakane's \gls{csa} \cite{Sad03}, using
    another permutation $\Psi[1..n]$ defined in \cite{GV00}, where $\Psi[i] = A^{-1}[A[i]+1]$. That is, for every $A[i]=k$ and $A[j]=k+1$, $\Psi[i]=j$.
    %For each position $j$ in $S$ pointed from $A[i]=j$, $\Psi[i]$ gives the position $z$ such that $A[z]$ points to $j+1$. 
    The special case when $A[i]=n$\footnote{$i=1$ if we use the unique terminator $\$$.} is handled as $\Psi[i]=A^{-1}[1]$, making a cycle.
    Therefore, the \gls{csa} is formed by $\Psi$, $D$, and $V$, which are sufficient to simulate binary searches of the interval $A[l..r]$ for the occurrences of $P$ without the need of accessing $A$ nor $S$. In this work, we define that operation as $[l..r]~\leftarrow~\bsearch(\Psi,P)$.
    The symbol $S[A[i]]$ pointed by $A[i]$ can be obtained as
    $V[\rank_1(D,i)]$. We can also easily obtain the following symbol from the source sequence  $S[A[i]+1]$ as
    $V[\rank_1(D, \Psi[i])]$, $S[A[i]+2]$ can be obtained as $V[\rank_1(D, \Psi[\Psi[i]])]$, and so on.
    %Therefore, the \gls{csa} replaces $S$, and it does not need $A$ anymore to perform searches.
    
    Although an uncompressed $\Psi$ would have the same space requirements
    as $A$, it is highly compressible, since it is formed by $\sigma$ strictly increasing subsequences. By using $\delta$-codes of the gaps (differences of each value with respect to the previous one) we are able to compress $\Psi$ to around the zero-order entropy of $S$~\cite{Sad03}, with $nH_0(S)+O(n\log\log\sigma)$ bits.
    In \cite{NM07} it has been further proved that $\Psi$ can be split into
    at most $nH_k+\sigma^k$ (for any $k$) {\em runs} of consecutive values so
    that the differences within those runs are always $1$. This allows for a combination of $\delta$-coding of gaps with run-length
    encoding (of $1$-$runs$) to achieve a higher-order compression of $\Psi$ without further intervention.
    In addition, to maintain fast random access to $\Psi$, absolute
    samples at regular intervals (every $t_{\Psi}$ entries) are kept. Parameter
    $t_{\Psi}$ implies a space/time trade-off. Larger values lead to better compression of $\Psi$ but slow down access time to non-sampled $\Psi[i]$ values.
    
    In \cite{FBNCPR12}, the authors have adapted Sadakane's \gls{csa} to deal with large (integer-based) alphabets
    and created the {\em integer-based CSA} ($iCSA$). They also showed that, in their scenario (natural language text indexing), the best
    compression of $\Psi$ was obtained by combining differential encoding of runs with Huffman and
    run-length encoding.

%\include{1-ctr}
	
%\include{2-xctr}
	
%\include{3-gis}

\part{Thesis summary} \label{part:final}
\chapter{Conclusions and future works}
\label{ch:concl}
	In transportation systems from \textit{smart cities}, new technologies such as traffic monitoring, automatic fare collection (e.g., smartcards) and automatic passenger counting have made possible to generate a huge amount of highly detailed,
	real-time data useful to define measures that characterize  a transportation network. This data is particularly useful because it actually consists of real trips, combining implicitly the demand of the system with either the street network or the service offered by a public transportation system with  the demand for the system.
	
	At the same time, analyzing these historic records about the demand of the network is within the interest of transportation agencies, as well as other entities that may be interested in studying the movements of crowds in an urban context. To make this kind of analysis possible, we have proposed powerful representations based on compact data structures that can easily be adapted for both urban transportation contexts (streets and most public transportation systems), that can handle diverse use cases with considerable memory and time efficiency.
	
	In addition, we have developed a \gls{gis} interface that integrates the compact representations developed, making it possible to analyze the stored information by an end user in a simple way, not requiring them to have a previous knowledge of the underlying technologies. Furthermore, this user interface further validates the use of an approach based on compact data structures, thus proving that it is possible to develop a competitive product that may be adopted by an organization.
	
	Finally, in the context of compact data structures research, we believe that this work may open a new field of practical applications for these structures and algorithms, as have been previously done for the fields of \textit{information retrieval} and \textit{bioinformatics}.
	
	\section{Contributions}
	The following list summarizes the main contributions in our work:
	
	\begin{enumerate}
	    \item In the context of trips over urban street networks, we have developed a representation based on a modified \gls{csa} and different alternatives of the \gls{wt} called \gls{ctr}, which requires as little as a 36\% of the size of an uncompressed baseline, while handling spatio-temporal queries in the order of several \micro s, while offering configurable trade-offs.
	    
	    \item We have proposed an extensible model for the representation of trips over a public transportation network, that may be adapted for most transportation systems of the world.
	    
	    \item We have developed two alternative representations for the context of trips over public transportation networks, \gls{ttctr} and \gls{xctr}, based on the same structures of \gls{ctr}, which can solve most of our proposed queries about network-aware trip patterns in the order of several \micro s, while needing only about 50\% of space compared to a plain (unindexed) representation.
	    
	    \item We have presented a scheme to compress \gls{sat} without affecting the temporal complexity of its operations, and we applied it in \gls{tm} as a structure to accelerate network load queries in the public transportation context.
	    
	    \item We have developed an user interface to analyze the demand of public transportation networks based on our proposed representations, as well as \gls{gis} technologies. 
	\end{enumerate}
	
	\section{Future work}
	While there are many possible future developments for our proposed representations for trips over public transportation networks, we are mostly concerned with finding a single representation that can efficiently handle both kinds of proposed queries in the Section~\ref{sec:newctr:desc}: the network load and the trip pattern ones. Finding such a representation is proving quite challenging, as most solutions that allow to efficiently aggregate multidimensional data (such as stops and times or journeys) cannot support most of our trip pattern queries.
	
	In the other hand, our proposed interface is still under development, where our most urgent goals is to support an intuitive visualization for lines that may enable the user to perform queries over them, as well as the addition of means to query the histogram endpoint, to display the usage of a stop or a line over time with dynamic charts. Finally, this interface may be improved to support different interactive visualizations for the total network usage over all the lines within a time range, in addition to reachability queries, where given a stop in the network we are interested in obtaining the average time taken to arrive to any other stop.
	
% \nocite{*}
% \bibliographystyle{apalike}
\bibliographystyle{alpha}
\addcontentsline{toc}{chapter}{\bibname}
\bibliography{thesis}

\vfill \pagebreak \thispagestyle{empty} \mbox{}
\vfill \pagebreak \mbox{} \thispagestyle{empty}

\end{document}
%###

% List of frogs:
% use greek letters (Lambda, etc) for sets of lines and stops, so they are not confused with query subindices
% theorems and corollaries for part I!
% TTCTRq and XCTRq
% remembah: you don't always have a factor of log(\bar{J^l}) for obtaining jcodes because it would be everywhere, and have little to do with the repr themselves. You did not want to use a bitvector because "space".
% remove leaflet duplicated url, and maybe others
% \em vs \textit

